{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stage 1 ODE block.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVZtMGA2xlIP"
      },
      "source": [
        "# Modified from https://github.com/Harrypotterrrr/DVD-GAN\n",
        "# Be careful when running with your computer with less than 25GB of RAM, it will crash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB2Ptmlrx1YI",
        "outputId": "1b81dae8-23ec-47ad-eb75-684d3cfa7e91"
      },
      "source": [
        "!pip install torchdiffeq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.9.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq) (3.7.4.3)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iExdrSrFVNz7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "\n",
        "from torchdiffeq import odeint_adjoint, odeint"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HR48Uf5L3Ld"
      },
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4B3BrhcS10u"
      },
      "source": [
        "class SpectralNorm(nn.Module):\n",
        "    def __init__(self, module, name='weight', power_iterations=1):\n",
        "        super(SpectralNorm, self).__init__()\n",
        "        self.module = module\n",
        "        self.name = name\n",
        "        self.power_iterations = power_iterations\n",
        "        if not self._made_params():\n",
        "            self._make_params()\n",
        "\n",
        "    def _update_u_v(self):\n",
        "        u = getattr(self.module.layer, self.name + \"_u\")\n",
        "        v = getattr(self.module.layer, self.name + \"_v\")\n",
        "        w = getattr(self.module.layer, self.name + \"_bar\")\n",
        "\n",
        "        height = w.data.shape[0]\n",
        "        for _ in range(self.power_iterations):\n",
        "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
        "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
        "\n",
        "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
        "        sigma = u.dot(w.view(height, -1).mv(v))\n",
        "        setattr(self.module.layer, self.name, w / sigma.expand_as(w))\n",
        "\n",
        "    def _made_params(self):\n",
        "        try:\n",
        "            u = getattr(self.module.layer, self.name + \"_u\")\n",
        "            v = getattr(self.module.layer, self.name + \"_v\")\n",
        "            w = getattr(self.module.layer, self.name + \"_bar\")\n",
        "            return True\n",
        "        except AttributeError:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def _make_params(self):\n",
        "        w = getattr(self.module.layer, self.name)\n",
        "\n",
        "        height = w.data.shape[0]\n",
        "        width = w.view(height, -1).data.shape[1]\n",
        "\n",
        "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
        "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
        "        u.data = l2normalize(u.data)\n",
        "        v.data = l2normalize(v.data)\n",
        "        w_bar = Parameter(w.data)\n",
        "\n",
        "        del self.module.layer._parameters[self.name]\n",
        "\n",
        "        self.module.layer.register_parameter(self.name + \"_u\", u)\n",
        "        self.module.layer.register_parameter(self.name + \"_v\", v)\n",
        "        self.module.layer.register_parameter(self.name + \"_bar\", w_bar)\n",
        "\n",
        "\n",
        "    def forward(self, *args):\n",
        "        self._update_u_v()\n",
        "        return self.module.forward(*args)\n",
        "\n",
        "def l2normalize(v, eps=1e-12):\n",
        "    return v / (v.norm() + eps)\n",
        "\n",
        "\n",
        "class ConditionalNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channel, n_condition=96):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channel = in_channel\n",
        "        self.bn = nn.BatchNorm2d(self.in_channel, affine=False)\n",
        "\n",
        "        self.embed = nn.Linear(n_condition, self.in_channel * 2)\n",
        "        self.embed.weight.data[:, :self.in_channel].normal_(1, 0.02)\n",
        "        self.embed.weight.data[:, self.in_channel:].zero_()\n",
        "\n",
        "    def forward(self, x, class_id):\n",
        "        out = self.bn(x)\n",
        "        embed = self.embed(class_id)\n",
        "        gamma, beta = embed.chunk(2, 1)\n",
        "        # gamma = gamma.unsqueeze(2).unsqueeze(3)\n",
        "        # beta = beta.unsqueeze(2).unsqueeze(3)\n",
        "        gamma = gamma.view(-1, self.in_channel, 1, 1)\n",
        "        beta = beta.view(-1, self.in_channel, 1, 1)\n",
        "        out = gamma * out + beta\n",
        "\n",
        "        return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kdaeDHuL50D"
      },
      "source": [
        "# ODE fucntion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBoZj1xbU5jV"
      },
      "source": [
        "class Conv2dODE(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, ksize=3, stride=1, \n",
        "                 padding=0, bias=True):\n",
        "        super().__init__()\n",
        "        # for augmented\n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.layer = nn.Conv2d(out_channel,out_channel,ksize,stride,padding,bias = bias)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        BT, C, W, H = x.size()\n",
        "        # zeros augmented\n",
        "        if self.in_channel < self.out_channel:\n",
        "            zeros_aug = torch.zeros([BT, self.out_channel - self.in_channel, W, H])\n",
        "            x = torch.cat((x,zeros_aug),1)\n",
        "        x = x * t\n",
        "        return self.layer(x)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjhGMM72iSaP"
      },
      "source": [
        "class ODEFunc(nn.Module):\n",
        "    #                   3           10          [3,3]\n",
        "    def __init__(self, in_channel, out_channel, kernel_size=None,\n",
        "                 padding=1, stride=1, n_class=96, bn=True,\n",
        "                 activation=F.relu, upsample_factor=2, downsample_factor=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.upsample_factor = upsample_factor if downsample_factor is 1 else 1\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.activation = activation\n",
        "        self.bn = bn if downsample_factor is 1 else False\n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.n_class = n_class\n",
        "\n",
        "        self.nfe = 0\n",
        "\n",
        "        if kernel_size is None:\n",
        "            kernel_size = [3, 3]\n",
        "        \n",
        "        self.conv0 = SpectralNorm(Conv2dODE(out_channel, out_channel, \n",
        "                                            kernel_size, stride, padding, \n",
        "                                            bias = True))\n",
        "\n",
        "        self.conv1 = SpectralNorm(Conv2dODE(out_channel, out_channel, \n",
        "                                            kernel_size, stride, padding,\n",
        "                                            bias = True))\n",
        "        \n",
        "\n",
        "        if bn:\n",
        "        #     self.CBNorm1 = ConditionalNorm(in_channel, n_class) # TODO 2 x noise.size[1]\n",
        "            self.CBNorm2 = ConditionalNorm(out_channel, n_class)\n",
        "        \n",
        "    def forward(self, t, x, condition):\n",
        "        self.nfe += 1\n",
        "        BT, C, W, H = x.size()\n",
        "        out = x\n",
        "        out = self.conv0(t,out)\n",
        "        if self.bn:\n",
        "            out = self.CBNorm2(out, condition)\n",
        "        out = self.activation(out)\n",
        "        out = self.conv1(t,out)\n",
        "        if self.downsample_factor != 1:\n",
        "            out = F.avg_pool2d(out, self.downsample_factor)\n",
        "        return out\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN02uXJoL-6j"
      },
      "source": [
        "# ODE Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWT28a8Hljah"
      },
      "source": [
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, odefunc):\n",
        "        super().__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0,1]).float()\n",
        "\n",
        "        if self.odefunc.bn:\n",
        "            self.CBNorm1 = ConditionalNorm(self.odefunc.in_channel, self.odefunc.n_class) # TODO 2 x noise.size[1]\n",
        "            # self.CBNorm2 = ConditionalNorm(out_channel, n_class)\n",
        "\n",
        "    def forward(self, x, condition):\n",
        "        out = x\n",
        "        if self.odefunc.bn:\n",
        "            out = self.CBNorm1(out,condition)\n",
        "    \n",
        "        out = self.odefunc.activation(out)\n",
        "        # print(out.size())\n",
        "        if self.odefunc.upsample_factor != 1:\n",
        "            out = F.interpolate(out, scale_factor=self.odefunc.upsample_factor)\n",
        "        # print(out.size())\n",
        "        BT, C, W, H = out.size()\n",
        "        # zeros augmented\n",
        "        if self.odefunc.in_channel < self.odefunc.out_channel:\n",
        "            zeros_aug = torch.zeros([BT, self.odefunc.out_channel - self.odefunc.in_channel, W, H])\n",
        "            out = torch.cat((out,zeros_aug),1)\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        # print('out',out.size())\n",
        "        func = lambda t,x: self.odefunc(t,x,condition)\n",
        "        out = odeint(func, out, self.integration_time)\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viwNk1jIoPUr",
        "outputId": "002b7982-efdf-4281-f6ea-95f36391abb1"
      },
      "source": [
        "n_class = 96\n",
        "batch_size = 4\n",
        "n_frames = 20\n",
        "\n",
        "gResBlock = ODEFunc(3, 100, [3, 3])\n",
        "odeGResBlock = ODEBlock(gResBlock)\n",
        "x = torch.rand([batch_size * n_frames, 3, 64, 64])\n",
        "condition = torch.rand([batch_size, n_class])\n",
        "condition = condition.repeat(n_frames, 1)\n",
        "print(x.size())\n",
        "y = odeGResBlock(x,condition)\n",
        "print(x.size())\n",
        "print(y.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([80, 3, 64, 64])\n",
            "torch.Size([80, 3, 128, 128])\n",
            "out torch.Size([80, 100, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhrBBALvyBkQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}